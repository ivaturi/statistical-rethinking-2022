
**Link to lecture**: https://www.youtube.com/watch?v=cclUd_HoRlo



#### Golems

Scientific models are like [golems](https://en.wikipedia.org/wiki/Golem); constructs engineered for specific purposes. These are neither true nor false, and can be unyielding in their logic. Golems themselves aren't wise; they are each useful in particular contexts (which is why there are so many diverse golems). A decision tree is an example of a golem. 

It is possible to learn and practice statistical science by learning a lot of different golems. This isn't good enough for research (specially research that pushes boundaries), because it is impossible to know what is and isn't appropriate beforehand. A golem cannot always discern when a context is inappropriate for its answers. This means a golem can fail in unpredictable ways when applied to a context it wasn't engineered for.

What is needed is a unified theory of golem engineering: a set of foundational principles for designing, building, and refining context-specific statistical models or procedures. The goal of this course, then, is to learn how to re-think statistical inference as a set of such strategies, instead of a bunch of predefined golems.


#### Rethinking

The goal of statistical inference is not to _test_ the [null hypothesis](https://en.wikipedia.org/wiki/Null_hypothesis)  (or alternately - to falsify the research hypothesis). Deductive falsification is nearly impossible because:

* A hypothesis, by itself, isn't useful unless it is supported by a set of cause-effect relationships that are also validated by some data. *Process models* formally describe causal structures, and *statistical models* describe the associations between causes and their effects.  This makes it hard to falsify unique null hypothesis:
	* a statistical model can correspond to more than one process model.
	* a hypothesis can correspond to more than one process model.
	* a statistical model can correspond to more than one hypothesis.

* Data, how it is collected, and how it is processed - are subject to:
	* observation errors; represented by false positives and false negatives
	* continuous hypotheses; most real-world hypotheses aren't black-or-white. Instead, they make claims about the distribution of data (or the frequency of observations)

* Falsification is a consensus-driven activity. Scientific communities come to _regard_ certain hypotheses as false (such as the geocentric model of the universe) but this is done by consensus, and not always because of evidence. 







